---
title: Seriously, Bro, You Actually Wrote It?
categories: Coding
date: 2026-01-14 22:12:22
tags: ['opencode', 'AI programming', 'code generation', 'remote development', 'devpod', 'aider', 'openhands', 'DeepSeek', 'automation tools']
---

The new year has brought another AI surprise...

<!-- more -->

Last week I kept seeing recommendations for [opencode](https://github.com/anomalyco/opencode), claiming it’s currently the best open‑source Claude Code alternative, with a pretty impressive success rate in writing executable code.

Of course I was skeptical at first. After all, I’ve used aider and openhands—they’re both good tools, but when paired with DeepSeek, the results were often… let’s say mixed. Many times they couldn’t quite grasp what I meant. Even after tweaking prompts with other AIs, they still struggled with tasks that were just a little more complex.

But with so many people praising it, I figured I’d give it a try. And wow—it actually exceeded my expectations.

As I mentioned last year, {% post_link 使用devpod设置自部署的codespace I really wanted a tool that could quickly spin up VS Code on a remote machine %}, but due to limited time and skill, I hadn’t started building it before I discovered devpod, which solved about 70% of my needs… so I lost motivation to write my own…

Back then I tried both aider and openhands to give me a basic framework. My requirements were fairly simple: automatically install VS Code server on a remote machine, forward the target port to my local machine, and try to follow devpod’s source code or directly use its interfaces.

Neither worked well. I ended up having to read the code myself with Copilot’s help, but I understood it very slowly, and I couldn’t even get devpod’s interfaces to work properly…

But openencode—it produced a working demo in one shot, using the same model, DeepSeek. Although it didn’t fully meet the requirement of closely following devpod’s approach, the fact that it delivered a runnable program that matched my functional description on the first attempt is, in my book, seriously impressive.

After the first version, I asked openencode to make three more modifications. Except for one time when it stopped before finishing, the other two went smoothly. That really surprised me.

Sure, it consumes tokens like crazy, but I’m using DeepSeek‑Chat—over the past year I’ve only spent about 25 yuan… This test cost me just two or three yuan, which I’m totally fine with.

Also, after this trial, my opinion of Manus has changed a bit. Maybe they really do have something! It turns out that prompt and engineering optimizations can indeed bring noticeable improvements… As always, practice reveals the truth… It’s just… I wish the cost of trying things out could be a bit lower…
